{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tZhd_ImG_Tx4i54mk-kpwrDmCCT3clOp",
      "authorship_tag": "ABX9TyMN6Q7xNxS9fL+LeRxNsRjH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "If you see this, it's successfully commited"
      ],
      "metadata": {
        "id": "Zzr2mghzXqBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "Qf7qtBpzdqwV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "neon19HUJg1E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "3y6dAzzrJf20"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Yandex Big Data Colab/data/\"\n",
        "\n",
        "shows_log = spark.sparkContext.textFile(path + \"shows-log2\")\n",
        "clicks_log = spark.sparkContext.textFile(path + \"clicks-log\")\n",
        "banners_dict = spark.sparkContext.textFile(path + \"banners_dict\")\n",
        "banner_info = spark.sparkContext.textFile(path + \"banner_info\")\n",
        "user_profile = spark.sparkContext.textFile(path + \"user_profile\")\n",
        "\n",
        "shows_log = spark.sparkContext.textFile(\"/content/drive/MyDrive/Yandex Big Data Colab/shows-log\")"
      ],
      "metadata": {
        "id": "YZomX3KHa8Ik"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in user_profile.collect():\n",
        "    print(i)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fB0G5sU2D_dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from types import LambdaType\n",
        "import json\n",
        "from pyspark.sql.functions import lit, udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql import Row\n",
        "\n",
        "def from_data_to_rdd(symbol=\"\\t\"):\n",
        "    def f(data):\n",
        "        return tuple(data.split(symbol))\n",
        "    return f\n",
        "\n",
        "def convert_json_to_dict(x):\n",
        "    res = json.loads(x)\n",
        "    res[\"uid\"] = str(res[\"uid\"])\n",
        "    return res\n",
        "\n",
        "def convert_json_to_rdd(rdd):\n",
        "    return rdd.map(convert_json_to_dict).map(lambda x: tuple(i for i in x.values()))\n",
        "\n",
        "def get_revenue(event1, event2, revenue):\n",
        "    if event1 == event2:\n",
        "        return revenue\n",
        "    return \"0\"\n",
        "\n",
        "def join_with_tabs(x):\n",
        "    return \"\\t\".join(x)\n",
        "\n",
        "def get_fixNone(n):\n",
        "    def f(x):\n",
        "        if x[0] == None:\n",
        "            x = (\"None\",)+(x[1],)\n",
        "        if x[1][1] == None:\n",
        "            if n == 1:\n",
        "                x = (x[0],)+((x[1][0], \"None\"),)\n",
        "            else:\n",
        "                x = (x[0],)+((x[1][0], (\"None\",)*n),)\n",
        "        return x\n",
        "    return f\n",
        "\n",
        "def process(shows, clicks, banners_dict, banner_info, user_profile):\n",
        "    # convert to rdd\n",
        "    clicks = clicks.map(from_data_to_rdd()) # dt, uid, banner_id\n",
        "    banners_dict = banners_dict.map(from_data_to_rdd()) # banner_id, banner_type\n",
        "    shows = shows.map(from_data_to_rdd()) # dt, uid, banner_id, banner_type\n",
        "    banner_info = banner_info.map(from_data_to_rdd(\",\")) # banner_type, pay_event_type, currency, cost\n",
        "    user_profile = convert_json_to_rdd(user_profile) # age, uid, gender\n",
        "\n",
        "    # step 1\n",
        "    clicks = clicks.map(lambda x: (x[2], (x[1], x[0]))) # banner_id, (uid, dt)\n",
        "    clicks_typed = clicks.leftOuterJoin(banners_dict) # banner_id, ((uid, dt), banner_type)\n",
        "    clicks_typed = clicks_typed.map(get_fixNone(1))\n",
        "\n",
        "    # step 2\n",
        "    clicks_typed = clicks_typed.map(lambda x: (x[1][1], (*x[1][0], x[0], \"click\"))) # banner_type, (uid, dt, banner_id, event_type)\n",
        "    shows = shows.map(lambda x: (x[3], (x[1], x[0], x[2], \"show\"))) # banner_type, (uid, dt, banner_id, event_type)\n",
        "    union = clicks_typed.union(shows)\n",
        "    #union = shows\n",
        "\n",
        "    # step 3\n",
        "    banner_info = banner_info.map(lambda x: (x[0], (*x[1:],))) # banner_type, (pay_event_type, currency, cost)\n",
        "    union_revenue = union.leftOuterJoin(banner_info) # banner_type, ((uid, dt, banner_id, event_type), (pay_event_type, currency, cost))\n",
        "    union_revenue = union_revenue.map(get_fixNone(3))\n",
        "    union_revenue = union_revenue.map(lambda x:(\n",
        "                                      x[1][0][0], (*x[1][0][1:], *x[1][1], x[0], get_revenue( x[1][0][3], x[1][1][0], x[1][1][2]))\n",
        "                                       )) # uid, (dt, banner_id, event_type,  pay_event_type, currency, cost,  banner_type,  revenue)\n",
        "\n",
        "    # step 4\n",
        "    user_profile = user_profile.map(lambda x: (x[1], (x[0], x[2]))) # uid, (age, gender)\n",
        "    res = union_revenue.leftOuterJoin(user_profile) # uid, ((dt, banner_id, event_type, pay_event_type, currency, cost, banner_type, revenue), (age, gender))\n",
        "    res = res.map(get_fixNone(2))\n",
        "    # convert result\n",
        "    res = res.map(lambda x: (\n",
        "                  x[1][0][0], x[1][0][2], x[0], x[1][0][1], x[1][0][6], *x[1][1], *x[1][0][3:5], x[1][0][7]\n",
        "                  )) # dt, event_type, uid, banner_id, banner_type, age, gender, pay_event_type, currency, revenue\n",
        "    res = res.map(join_with_tabs)\n",
        "\n",
        "    return res # res.groupBy(lambda x: x).map(lambda x: x[0])\n",
        ""
      ],
      "metadata": {
        "id": "ux_-G9YMNoyF"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = process(shows_log, clicks_log, banners_dict, banner_info, user_profile)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "pHhaIZsstTAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = False\n",
        "for i in result.collect():\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "Mn995ODW87XR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "uBr1irEbtTUZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}